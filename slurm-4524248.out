device = cuda
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:18<?, ?it/s]
{'node1': tensor([[0.0559],
        [0.1688],
        [0.1974],
        ...,
        [0.3472],
        [0.2033],
        [0.1410]], device='cuda:0'), 'node2': tensor([[0.0559],
        [0.1688],
        [0.1974],
        ...,
        [0.3472],
        [0.2033],
        [0.1410]], device='cuda:0'), 'node3': tensor([[0.0559],
        [0.1688],
        [0.1974],
        ...,
        [0.3472],
        [0.2033],
        [0.1410]], device='cuda:0'), 'node4': tensor([[0.0559],
        [0.1688],
        [0.1974],
        ...,
        [0.3472],
        [0.2033],
        [0.1410]], device='cuda:0'), 'node5': tensor([[0.0559],
        [0.1688],
        [0.1974],
        ...,
        [0.3472],
        [0.2033],
        [0.1410]], device='cuda:0')}
dict_keys(['node1', 'node2', 'node3', 'node4', 'node5'])
{'node1': tensor([[-0.0119, -0.0020, -0.0121,  ...,  0.0016,  0.0134,  0.0124],
        [-0.0119, -0.0020, -0.0121,  ...,  0.0016,  0.0134,  0.0124],
        [-0.0119, -0.0020, -0.0122,  ...,  0.0016,  0.0134,  0.0124],
        ...,
        [-0.0166, -0.0028, -0.0170,  ...,  0.0022,  0.0187,  0.0173],
        [-0.0166, -0.0028, -0.0170,  ...,  0.0022,  0.0187,  0.0173],
        [-0.0166, -0.0028, -0.0170,  ...,  0.0022,  0.0187,  0.0173]],
       device='cuda:0', grad_fn=<SumBackward1>), 'node2': tensor([[ 0.0064, -0.0104, -0.0065,  ...,  0.0349,  0.0055, -0.0074],
        [ 0.0064, -0.0104, -0.0065,  ...,  0.0349,  0.0055, -0.0074],
        [ 0.0064, -0.0104, -0.0065,  ...,  0.0348,  0.0055, -0.0074],
        ...,
        [ 0.0098, -0.0159, -0.0099,  ...,  0.0533,  0.0084, -0.0113],
        [ 0.0097, -0.0157, -0.0098,  ...,  0.0527,  0.0084, -0.0112],
        [ 0.0098, -0.0158, -0.0098,  ...,  0.0530,  0.0084, -0.0113]],
       device='cuda:0', grad_fn=<SumBackward1>), 'node3': tensor([[-0.0084, -0.0539,  0.0208,  ...,  0.0051,  0.0011,  0.0125],
        [-0.0085, -0.0544,  0.0210,  ...,  0.0052,  0.0012,  0.0126],
        [-0.0085, -0.0543,  0.0210,  ...,  0.0052,  0.0012,  0.0126],
        ...,
        [-0.0084, -0.0537,  0.0207,  ...,  0.0051,  0.0011,  0.0125],
        [-0.0084, -0.0539,  0.0208,  ...,  0.0051,  0.0011,  0.0125],
        [-0.0085, -0.0540,  0.0208,  ...,  0.0051,  0.0011,  0.0125]],
       device='cuda:0', grad_fn=<SumBackward1>), 'node4': tensor([[ 0.0038,  0.0147,  0.0038,  ...,  0.0275, -0.0060,  0.0072],
        [ 0.0042,  0.0162,  0.0042,  ...,  0.0302, -0.0066,  0.0079],
        [ 0.0057,  0.0219,  0.0057,  ...,  0.0410, -0.0089,  0.0107],
        ...,
        [ 0.0078,  0.0303,  0.0079,  ...,  0.0565, -0.0123,  0.0148],
        [ 0.0055,  0.0213,  0.0055,  ...,  0.0398, -0.0086,  0.0104],
        [ 0.0044,  0.0170,  0.0044,  ...,  0.0318, -0.0069,  0.0083]],
       device='cuda:0', grad_fn=<SumBackward1>), 'node5': tensor([[0.0006, 0.0011, 0.0004,  ..., 0.0056, 0.0015, 0.0031],
        [0.0019, 0.0032, 0.0012,  ..., 0.0169, 0.0045, 0.0092],
        [0.0022, 0.0037, 0.0014,  ..., 0.0198, 0.0053, 0.0108],
        ...,
        [0.0038, 0.0066, 0.0025,  ..., 0.0348, 0.0093, 0.0190],
        [0.0022, 0.0038, 0.0015,  ..., 0.0203, 0.0055, 0.0111],
        [0.0016, 0.0027, 0.0010,  ..., 0.0141, 0.0038, 0.0077]],
       device='cuda:0', grad_fn=<SumBackward1>)}
Traceback (most recent call last):
  File "/project/p_gnn001/code/tsp/tsp/train2.py", line 328, in <module>
    main()
  File "/project/p_gnn001/code/tsp/tsp/train2.py", line 321, in main
    val_loss = run(args)
               ^^^^^^^^^
  File "/project/p_gnn001/code/tsp/tsp/train2.py", line 213, in run
    epoch_loss = train(model, train_loader, args.target, criterion, optimizer, device)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/p_gnn001/code/tsp/tsp/train2.py", line 50, in train
    y_pred = model(batch, x)
             ^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/p_gnn001/code/tsp/tsp/gnngls/models.py", line 173, in forward
    h = MLP(torch.cat(list(h.values()), dim=1))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: MLP.__init__() missing 2 required positional arguments: 'hidden_dim' and 'output_dim'
