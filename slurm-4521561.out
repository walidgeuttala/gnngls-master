device = cuda
  0%|          | 0/10 [00:00<?, ?it/s]/project/p_gnn001/code/tsp/tsp/gnngls/models.py:94: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).flatten(-1)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/loss.py:993: UserWarning: Using a target size (torch.Size([60480, 1])) that is different to the input size (torch.Size([63, 960])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.huber_loss(input, target, reduction=self.reduction, delta=self.delta)
  0%|          | 0/10 [00:06<?, ?it/s]
Traceback (most recent call last):
  File "/project/p_gnn001/code/tsp/tsp/train2.py", line 322, in <module>
    main()
  File "/project/p_gnn001/code/tsp/tsp/train2.py", line 315, in main
    val_loss = run(args)
               ^^^^^^^^^
  File "/project/p_gnn001/code/tsp/tsp/train2.py", line 207, in run
    epoch_loss = train(model, train_loader, args.target, criterion, optimizer, device)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/p_gnn001/code/tsp/tsp/train2.py", line 51, in train
    loss = criterion(y_pred, y.type_as(y_pred))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/loss.py", line 993, in forward
    return F.huber_loss(input, target, reduction=self.reduction, delta=self.delta)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/functional.py", line 3277, in huber_loss
    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/functional.py", line 76, in broadcast_tensors
    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: The size of tensor a (63) must match the size of tensor b (60480) at non-singleton dimension 0
