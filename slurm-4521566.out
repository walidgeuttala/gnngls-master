device = cuda
  0%|          | 0/10 [00:00<?, ?it/s]/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([20160, 1])
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
  0%|          | 0/10 [00:57<?, ?it/s, Train Loss=0.4990, Validation Loss=0.4990, correlation : =nan, cosin correlation : =0.9999, gap : =210.4792] 10%|█         | 1/10 [00:57<08:41, 57.91s/it, Train Loss=0.4990, Validation Loss=0.4990, correlation : =nan, cosin correlation : =0.9999, gap : =210.4792]torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([20160, 1])
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
 10%|█         | 1/10 [01:57<08:41, 57.91s/it, Train Loss=0.4990, Validation Loss=0.4990, correlation : =nan, cosin correlation : =0.9999, gap : =210.4792] 20%|██        | 2/10 [01:57<07:49, 58.74s/it, Train Loss=0.4990, Validation Loss=0.4990, correlation : =nan, cosin correlation : =0.9999, gap : =210.4792]torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([20160, 1])
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
 20%|██        | 2/10 [02:55<07:49, 58.74s/it, Train Loss=0.4990, Validation Loss=0.4990, correlation : =nan, cosin correlation : =0.9999, gap : =210.4792] 30%|███       | 3/10 [02:55<06:48, 58.32s/it, Train Loss=0.4990, Validation Loss=0.4990, correlation : =nan, cosin correlation : =0.9999, gap : =210.4792]torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([20160, 1])
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
 30%|███       | 3/10 [03:52<06:48, 58.32s/it, Train Loss=0.4990, Validation Loss=0.4990, correlation : =nan, cosin correlation : =1.0000, gap : =210.4792] 40%|████      | 4/10 [03:52<05:47, 57.99s/it, Train Loss=0.4990, Validation Loss=0.4990, correlation : =nan, cosin correlation : =1.0000, gap : =210.4792]torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([20160, 1])
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
 40%|████      | 4/10 [04:49<05:47, 57.99s/it, Train Loss=0.4990, Validation Loss=0.4990, correlation : =nan, cosin correlation : =1.0000, gap : =210.4792] 50%|█████     | 5/10 [04:49<04:48, 57.65s/it, Train Loss=0.4990, Validation Loss=0.4990, correlation : =nan, cosin correlation : =1.0000, gap : =210.4792]torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([60480, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
torch.Size([4032, 1])
/project/p_gnn001/code/tsp/tsp/gnngls/models.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return torch.nn.functional.softmax(h.view(63, h.shape[0]//63)).view(sh)
slurmstepd: error: *** JOB 4521566 ON x1001c0s0b0n0 CANCELLED AT 2024-04-23T21:37:56 ***
