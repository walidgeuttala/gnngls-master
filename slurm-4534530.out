device = cuda
Traceback (most recent call last):
  File "/project/p_gnn001/code/tsp/tsp/test.py", line 104, in <module>
    model.load_state_dict(checkpoint['model_state_dict'])
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 2153, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for EdgePropertyPredictionModel:
	Missing key(s) in state_dict: "embed_layer.weight", "embed_layer.bias", "message_passing_layers.0.message_passing.module.attn_l", "message_passing_layers.0.message_passing.module.attn_r", "message_passing_layers.0.message_passing.module.bias", "message_passing_layers.0.message_passing.module.fc.weight", "message_passing_layers.0.feed_forward.0.weight", "message_passing_layers.0.feed_forward.0.bias", "message_passing_layers.0.feed_forward.0.running_mean", "message_passing_layers.0.feed_forward.0.running_var", "message_passing_layers.0.feed_forward.1.module.0.weight", "message_passing_layers.0.feed_forward.1.module.0.bias", "message_passing_layers.0.feed_forward.1.module.2.weight", "message_passing_layers.0.feed_forward.1.module.2.bias", "message_passing_layers.0.feed_forward.2.weight", "message_passing_layers.0.feed_forward.2.bias", "message_passing_layers.0.feed_forward.2.running_mean", "message_passing_layers.0.feed_forward.2.running_var", "message_passing_layers.1.message_passing.module.attn_l", "message_passing_layers.1.message_passing.module.attn_r", "message_passing_layers.1.message_passing.module.bias", "message_passing_layers.1.message_passing.module.fc.weight", "message_passing_layers.1.feed_forward.0.weight", "message_passing_layers.1.feed_forward.0.bias", "message_passing_layers.1.feed_forward.0.running_mean", "message_passing_layers.1.feed_forward.0.running_var", "message_passing_layers.1.feed_forward.1.module.0.weight", "message_passing_layers.1.feed_forward.1.module.0.bias", "message_passing_layers.1.feed_forward.1.module.2.weight", "message_passing_layers.1.feed_forward.1.module.2.bias", "message_passing_layers.1.feed_forward.2.weight", "message_passing_layers.1.feed_forward.2.bias", "message_passing_layers.1.feed_forward.2.running_mean", "message_passing_layers.1.feed_forward.2.running_var", "message_passing_layers.2.message_passing.module.attn_l", "message_passing_layers.2.message_passing.module.attn_r", "message_passing_layers.2.message_passing.module.bias", "message_passing_layers.2.message_passing.module.fc.weight", "message_passing_layers.2.feed_forward.0.weight", "message_passing_layers.2.feed_forward.0.bias", "message_passing_layers.2.feed_forward.0.running_mean", "message_passing_layers.2.feed_forward.0.running_var", "message_passing_layers.2.feed_forward.1.module.0.weight", "message_passing_layers.2.feed_forward.1.module.0.bias", "message_passing_layers.2.feed_forward.1.module.2.weight", "message_passing_layers.2.feed_forward.1.module.2.bias", "message_passing_layers.2.feed_forward.2.weight", "message_passing_layers.2.feed_forward.2.bias", "message_passing_layers.2.feed_forward.2.running_mean", "message_passing_layers.2.feed_forward.2.running_var", "message_passing_layers.3.message_passing.module.attn_l", "message_passing_layers.3.message_passing.module.attn_r", "message_passing_layers.3.message_passing.module.bias", "message_passing_layers.3.message_passing.module.fc.weight", "message_passing_layers.3.feed_forward.0.weight", "message_passing_layers.3.feed_forward.0.bias", "message_passing_layers.3.feed_forward.0.running_mean", "message_passing_layers.3.feed_forward.0.running_var", "message_passing_layers.3.feed_forward.1.module.0.weight", "message_passing_layers.3.feed_forward.1.module.0.bias", "message_passing_layers.3.feed_forward.1.module.2.weight", "message_passing_layers.3.feed_forward.1.module.2.bias", "message_passing_layers.3.feed_forward.2.weight", "message_passing_layers.3.feed_forward.2.bias", "message_passing_layers.3.feed_forward.2.running_mean", "message_passing_layers.3.feed_forward.2.running_var", "message_passing_layers.4.message_passing.module.attn_l", "message_passing_layers.4.message_passing.module.attn_r", "message_passing_layers.4.message_passing.module.bias", "message_passing_layers.4.message_passing.module.fc.weight", "message_passing_layers.4.feed_forward.0.weight", "message_passing_layers.4.feed_forward.0.bias", "message_passing_layers.4.feed_forward.0.running_mean", "message_passing_layers.4.feed_forward.0.running_var", "message_passing_layers.4.feed_forward.1.module.0.weight", "message_passing_layers.4.feed_forward.1.module.0.bias", "message_passing_layers.4.feed_forward.1.module.2.weight", "message_passing_layers.4.feed_forward.1.module.2.bias", "message_passing_layers.4.feed_forward.2.weight", "message_passing_layers.4.feed_forward.2.bias", "message_passing_layers.4.feed_forward.2.running_mean", "message_passing_layers.4.feed_forward.2.running_var". 
	Unexpected key(s) in state_dict: "gnn_layers.0.mods.ss.attn_l", "gnn_layers.0.mods.ss.attn_r", "gnn_layers.0.mods.ss.bias", "gnn_layers.0.mods.ss.fc.weight", "gnn_layers.0.mods.st.attn_l", "gnn_layers.0.mods.st.attn_r", "gnn_layers.0.mods.st.bias", "gnn_layers.0.mods.st.fc.weight", "gnn_layers.0.mods.ts.attn_l", "gnn_layers.0.mods.ts.attn_r", "gnn_layers.0.mods.ts.bias", "gnn_layers.0.mods.ts.fc.weight", "gnn_layers.0.mods.tt.attn_l", "gnn_layers.0.mods.tt.attn_r", "gnn_layers.0.mods.tt.bias", "gnn_layers.0.mods.tt.fc.weight", "gnn_layers.0.mods.pp.attn_l", "gnn_layers.0.mods.pp.attn_r", "gnn_layers.0.mods.pp.bias", "gnn_layers.0.mods.pp.fc.weight", "gnn_layers.1.mods.ss.attn_l", "gnn_layers.1.mods.ss.attn_r", "gnn_layers.1.mods.ss.bias", "gnn_layers.1.mods.ss.fc.weight", "gnn_layers.1.mods.st.attn_l", "gnn_layers.1.mods.st.attn_r", "gnn_layers.1.mods.st.bias", "gnn_layers.1.mods.st.fc.weight", "gnn_layers.1.mods.ts.attn_l", "gnn_layers.1.mods.ts.attn_r", "gnn_layers.1.mods.ts.bias", "gnn_layers.1.mods.ts.fc.weight", "gnn_layers.1.mods.tt.attn_l", "gnn_layers.1.mods.tt.attn_r", "gnn_layers.1.mods.tt.bias", "gnn_layers.1.mods.tt.fc.weight", "gnn_layers.1.mods.pp.attn_l", "gnn_layers.1.mods.pp.attn_r", "gnn_layers.1.mods.pp.bias", "gnn_layers.1.mods.pp.fc.weight", "gnn_layers.2.mods.ss.attn_l", "gnn_layers.2.mods.ss.attn_r", "gnn_layers.2.mods.ss.bias", "gnn_layers.2.mods.ss.fc.weight", "gnn_layers.2.mods.st.attn_l", "gnn_layers.2.mods.st.attn_r", "gnn_layers.2.mods.st.bias", "gnn_layers.2.mods.st.fc.weight", "gnn_layers.2.mods.ts.attn_l", "gnn_layers.2.mods.ts.attn_r", "gnn_layers.2.mods.ts.bias", "gnn_layers.2.mods.ts.fc.weight", "gnn_layers.2.mods.tt.attn_l", "gnn_layers.2.mods.tt.attn_r", "gnn_layers.2.mods.tt.bias", "gnn_layers.2.mods.tt.fc.weight", "gnn_layers.2.mods.pp.attn_l", "gnn_layers.2.mods.pp.attn_r", "gnn_layers.2.mods.pp.bias", "gnn_layers.2.mods.pp.fc.weight", "gnn_layers.3.mods.ss.attn_l", "gnn_layers.3.mods.ss.attn_r", "gnn_layers.3.mods.ss.bias", "gnn_layers.3.mods.ss.fc.weight", "gnn_layers.3.mods.st.attn_l", "gnn_layers.3.mods.st.attn_r", "gnn_layers.3.mods.st.bias", "gnn_layers.3.mods.st.fc.weight", "gnn_layers.3.mods.ts.attn_l", "gnn_layers.3.mods.ts.attn_r", "gnn_layers.3.mods.ts.bias", "gnn_layers.3.mods.ts.fc.weight", "gnn_layers.3.mods.tt.attn_l", "gnn_layers.3.mods.tt.attn_r", "gnn_layers.3.mods.tt.bias", "gnn_layers.3.mods.tt.fc.weight", "gnn_layers.3.mods.pp.attn_l", "gnn_layers.3.mods.pp.attn_r", "gnn_layers.3.mods.pp.bias", "gnn_layers.3.mods.pp.fc.weight", "gnn_layers.4.mods.ss.attn_l", "gnn_layers.4.mods.ss.attn_r", "gnn_layers.4.mods.ss.bias", "gnn_layers.4.mods.ss.fc.weight", "gnn_layers.4.mods.st.attn_l", "gnn_layers.4.mods.st.attn_r", "gnn_layers.4.mods.st.bias", "gnn_layers.4.mods.st.fc.weight", "gnn_layers.4.mods.ts.attn_l", "gnn_layers.4.mods.ts.attn_r", "gnn_layers.4.mods.ts.bias", "gnn_layers.4.mods.ts.fc.weight", "gnn_layers.4.mods.tt.attn_l", "gnn_layers.4.mods.tt.attn_r", "gnn_layers.4.mods.tt.bias", "gnn_layers.4.mods.tt.fc.weight", "gnn_layers.4.mods.pp.attn_l", "gnn_layers.4.mods.pp.attn_r", "gnn_layers.4.mods.pp.bias", "gnn_layers.4.mods.pp.fc.weight", "embed_layer.0.linears.0.weight", "embed_layer.0.linears.1.weight", "embed_layer.0.batch_norm.weight", "embed_layer.0.batch_norm.bias", "embed_layer.0.batch_norm.running_mean", "embed_layer.0.batch_norm.running_var", "embed_layer.0.batch_norm.num_batches_tracked", "embed_layer.1.linears.0.weight", "embed_layer.1.linears.1.weight", "embed_layer.1.batch_norm.weight", "embed_layer.1.batch_norm.bias", "embed_layer.1.batch_norm.running_mean", "embed_layer.1.batch_norm.running_var", "embed_layer.1.batch_norm.num_batches_tracked", "embed_layer.2.linears.0.weight", "embed_layer.2.linears.1.weight", "embed_layer.2.batch_norm.weight", "embed_layer.2.batch_norm.bias", "embed_layer.2.batch_norm.running_mean", "embed_layer.2.batch_norm.running_var", "embed_layer.2.batch_norm.num_batches_tracked", "embed_layer.3.linears.0.weight", "embed_layer.3.linears.1.weight", "embed_layer.3.batch_norm.weight", "embed_layer.3.batch_norm.bias", "embed_layer.3.batch_norm.running_mean", "embed_layer.3.batch_norm.running_var", "embed_layer.3.batch_norm.num_batches_tracked", "embed_layer.4.linears.0.weight", "embed_layer.4.linears.1.weight", "embed_layer.4.batch_norm.weight", "embed_layer.4.batch_norm.bias", "embed_layer.4.batch_norm.running_mean", "embed_layer.4.batch_norm.running_var", "embed_layer.4.batch_norm.num_batches_tracked". 
	size mismatch for decision_layer.linears.0.weight: copying a param with shape torch.Size([128, 640]) from checkpoint, the shape in current model is torch.Size([128, 768]).
